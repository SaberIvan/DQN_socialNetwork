{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f098257",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Library functions\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "from matplotlib import animation\n",
    "import networkx.algorithms.centrality as nx_centrality\n",
    "from collections import deque\n",
    "from matplotlib import animation\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95025752",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## Training dataset\n",
    "The global parameters of the generate_random_graph function:\n",
    "1. FAKE_DIFF_ITER: the fake nodes diffusion iteration\n",
    "2. FAKE_SEED_NUM: the initial fake seed set number\n",
    "3. NODE_NUM: the graph nodes number\n",
    "4. EDGE_NUM: the graph edges number \n",
    "5. M_INDEX: the generate graph method index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11919e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_graph(difusion_iteration, method_index, fake_seed_num, num_nodes, num_edges, probability = 0.5,m = 2, radius = None, k_nearest_neighbor = None, degree = None, seed = None):\n",
    "    random_graph = nx.Graph()\n",
    "    if method_index == 0:\n",
    "        random_graph = nx.gnm_random_graph(num_nodes, num_edges)\n",
    "\n",
    "    elif method_index == 1:\n",
    "        random_graph = nx.erdos_renyi_graph(num_nodes, probability)\n",
    "\n",
    "    elif method_index == 2:\n",
    "         # m means the edges number from the create point to existing point\n",
    "        random_graph = nx.barabasi_albert_graph(num_nodes, m)\n",
    "\n",
    "    elif method_index == 3:\n",
    "        random_graph = nx.watts_strogatz_graph(num_nodes, k_nearest_neighbor, probability)\n",
    "    for (u,v) in random_graph.edges:\n",
    "        if FIXED == True:\n",
    "            random_graph.edges[u, v][\"weight\"] = PROBABILITY\n",
    "        else:\n",
    "            random_graph.edges[u, v][\"weight\"] =  random.uniform(0,1)\n",
    "    for node in random_graph.nodes():\n",
    "        random_graph.nodes[node]['state'] = 0 # 0初始状态；1:true；2:fake\n",
    "    node_number = random_graph.number_of_nodes()\n",
    "    start_node_index = [0] *fake_seed_num\n",
    "    index_range = range(0,  node_number)\n",
    "    fake_seed_set = random.sample(index_range, fake_seed_num)\n",
    "    fake_active_nodes = fake_seed_set.copy()\n",
    "    fake_nodes_set = fake_seed_set.copy()\n",
    "    for _ in range(difusion_iteration):\n",
    "        temp_fake = []\n",
    "        for v in fake_active_nodes:\n",
    "            for nbr in random_graph.neighbors(v): \n",
    "                if random_graph.nodes[nbr]['state'] == 0 : \n",
    "                    edge_data = random_graph.get_edge_data(v, nbr)\n",
    "                    if random.uniform(0, 1) < edge_data['weight']:\n",
    "                        fake_nodes_set.append(nbr)\n",
    "                        temp_fake.append(nbr)\n",
    "                        random_graph.nodes[nbr]['state'] = 2\n",
    "        fake_active_nodes = temp_fake.copy()\n",
    "        temp_fake.clear()    \n",
    "    for node in fake_nodes_set:\n",
    "        random_graph.nodes[node]['state'] = 2\n",
    "        \n",
    "    return random_graph,fake_active_nodes,fake_seed_set,fake_nodes_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34797e",
   "metadata": {},
   "source": [
    "## Create and normalize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196f3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc \n",
    "import scipy as sp\n",
    "import scipy.sparse  # call as sp.sparse\n",
    "import scipy.io as sio\n",
    "\n",
    "# filename_ca_HepTh = r\"D:\\course (Kou Hari)\\2023 semaster 1\\COMP5703 Capstone\\data\\ca-HepTh.mtx\"\n",
    "# filename_ca_GrQc = r\"D:\\course (Kou Hari)\\2023 semaster 1\\COMP5703 Capstone\\data\\ca-GrQc.mtx\"\n",
    "# filename_tech_p2p_gnutella = r\"D:\\course (Kou Hari)\\2023 semaster 1\\COMP5703 Capstone\\data\\tech-p2p-gnutella.mtx\"\n",
    "filename_ca_HepTh = 'ca-HepTh.mtx'\n",
    "filename_ca_GrQc = 'ca-GrQc.mtx'\n",
    "filename_tech_p2p_gnutella = 'tech-p2p-gnutella.mtx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d7c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(filename):\n",
    "    \n",
    "#     adata = sc.read(filename)\n",
    "#     sparse_matrix = sp.load_npz(filename)\n",
    "    data = sio.mmread(filename)\n",
    "    G = nx.from_scipy_sparse_array(data)\n",
    "#     G = nx.from_scipy_sparse_array(adata.X, create_using=nx.MultiGraph)\n",
    "    print(\"node number:\",G.number_of_nodes())\n",
    "    print(\"edge number:\",G.number_of_edges())\n",
    "    return G, G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff7710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node number: 9877\n",
      "edge number: 25998\n"
     ]
    }
   ],
   "source": [
    "G_ca_HepTh,N_ca_HepTh,E_ca_HepTh= read_graph(filename_ca_HepTh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa80b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node number: 5242\n",
      "edge number: 14496\n"
     ]
    }
   ],
   "source": [
    "G_ca_GrQc,N_ca_GrQc,E_ca_GrQc = read_graph(filename_ca_GrQc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e25f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node number: 62561\n",
      "edge number: 147878\n"
     ]
    }
   ],
   "source": [
    "G_tech_p2p_gnutella,N_tech_p2p_gnutella,E_tech_p2p_gnutella = read_graph(filename_tech_p2p_gnutella)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf089d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_graph(graph):\n",
    "    graph_node_number = graph.number_of_nodes()\n",
    "    graph_edge_number = graph.number_of_edges()\n",
    "    for node in graph.nodes():\n",
    "        graph.nodes[node]['state'] = 0\n",
    "    for (u,v) in graph.edges():\n",
    "        graph.edges[u,v]['weight'] = random.uniform(0,1)\n",
    "    return graph,graph_node_number,graph_edge_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10b47904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_nodes_diffusion(graph,fake_seed_num,iteration):\n",
    "    node_number = graph.number_of_nodes()\n",
    "    start_node_index = [0] *fake_seed_num\n",
    "    index_range = range(0,  node_number)\n",
    "    fake_seed_set = random.sample(index_range, fake_seed_num)\n",
    "    fake_active_nodes = fake_seed_set.copy()\n",
    "    fake_nodes_set = fake_seed_set.copy()\n",
    "    for node in fake_seed_set:\n",
    "        graph.nodes[node]['state'] = 2\n",
    "    #fake news diffusion\n",
    "    for _ in range(iteration):\n",
    "        temp_fake = []\n",
    "        for v in fake_active_nodes:\n",
    "            for nbr in graph.neighbors(v): \n",
    "                if graph.nodes[nbr]['state'] == 0 : \n",
    "                    edge_data = graph.get_edge_data(v, nbr)\n",
    "                    if random.uniform(0, 1) < edge_data['weight']:\n",
    "                        fake_nodes_set.append(nbr)\n",
    "                        temp_fake.append(nbr)\n",
    "                        graph.nodes[nbr]['state'] = 2\n",
    "        fake_active_nodes = temp_fake.copy()  \n",
    "    for node in fake_nodes_set:\n",
    "        random_graph.nodes[node]['state'] = 2\n",
    "    return graph,fake_active_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd43feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_draw_graph(Graph,draw = False):\n",
    "    color_list = []\n",
    "    fake = 0\n",
    "    true = 0\n",
    "    normal = 0\n",
    "    for node in Graph.nodes():\n",
    "        if Graph.nodes[node]['state'] == 0:\n",
    "            normal += 1\n",
    "            color_list.append('blue')\n",
    "        elif Graph.nodes[node]['state'] == 1:\n",
    "            true += 1\n",
    "            color_list.append('green')\n",
    "        elif Graph.nodes[node]['state'] == 2:\n",
    "            fake += 1\n",
    "            color_list.append('red')\n",
    "    print(\"normal nodes number:\",normal)\n",
    "    print(\"true nodes number:\",true)\n",
    "    print(\"fake nodes number:\",fake)\n",
    "    print(\"the edge of graph:\",Graph.number_of_edges())\n",
    "    #nx.draw(Graph, node_color= color_list) \n",
    "    if draw:\n",
    "        nx.draw_circular(Graph, node_color= color_list)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fed05d",
   "metadata": {},
   "source": [
    "# Environment Class\n",
    "The global parameters in the Environment Class:\n",
    "1. ITERATION: control the diffusion times during the true and fake nodes antagonistic process\n",
    "2. MAX_STEP: control the max step of this epoch\n",
    "3. SEED_SIZE: the initial size of the seed set, the initial parameters of Env class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd299845",
   "metadata": {},
   "source": [
    "The input variable of the Env() class:\n",
    "1. graph: the training graph or testing graph\n",
    "2. seed_size: SEED_SIZE;the initial size of the seed set\n",
    "3. fake_set: the initial fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485de98",
   "metadata": {},
   "source": [
    "The functions in the Env class:\n",
    "1. reset: reset the parameters\n",
    "2. step: the experiment excuation progress\n",
    "3. select_initial_seeds: select the initial seed randomly\n",
    "4. select_initial_seeds_rules: select the intial seed set according to different criterion\n",
    "5. add_seed: add the seed nodes according to the action number from the agent\n",
    "6. get_state: get the current state of the graph\n",
    "7. diffusion_process: the procees of the true and fake nodes antagonistic\n",
    "8. get_image: draw the image of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e323b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env():\n",
    "    def __init__(self, graph,seed_size,fake_set):\n",
    "        self.graph_initial = graph\n",
    "        self.seed_size = seed_size\n",
    "        self.seed_set = []\n",
    "        self.fake_set = fake_set\n",
    "        self.state = None\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        #select the seed set:\n",
    "        self.graph = self.graph_initial.copy()\n",
    "        self.step_count = 0\n",
    "        self.add_number = 0\n",
    "        self.seed_set, action = self.select_initial_seeds_rules(self.graph,self.seed_size)\n",
    "        self.true_active_nodes = self.seed_set.copy()\n",
    "        self.fake_active_nodes = self.fake_set.copy()\n",
    "        self.state = self.get_state()\n",
    "        return self.state, action\n",
    "    \n",
    "    def step(self,action):\n",
    "        count_state0 = 0\n",
    "        for node in self.graph.nodes():\n",
    "            if self.graph.nodes[node]['state'] == 0:\n",
    "                count_state0 += 1\n",
    "        if action > 0 and (len(self.seed_set) + ADD_SEED_NUMBER <= self.graph.number_of_nodes()) and count_state0 >= ADD_SEED_NUMBER:\n",
    "            self.add_number += 1\n",
    "            centrality_methods = [\"None\", \"random\", \"degree\", \"closeness\", \"betweenness\", \"eigenvector\"]\n",
    "            centrality_method = centrality_methods[action]\n",
    "            self.seed_set = self.add_seed(self.graph,self.seed_set,action,ADD_SEED_NUMBER)\n",
    "            if(self.true_active_nodes[-ADD_SEED_NUMBER:]!= self.seed_set[-ADD_SEED_NUMBER:]):\n",
    "                self.true_active_nodes.extend(self.seed_set[-ADD_SEED_NUMBER:])\n",
    "        self.graph,self.true_active_nodes,self.fake_active_nodes = self.diffusion_process(self.graph,\n",
    "                                                                                     self.true_active_nodes,\n",
    "                                                                               self.fake_active_nodes,ITERATION)\n",
    "        #print(\"current image:\")\n",
    "        #self.get_image(self.graph)\n",
    "        \n",
    "        # terminal condition                                                                    \n",
    "        all_true_nodes = []\n",
    "        all_fake_nodes = []\n",
    "        normal_nodes= []                                                                             \n",
    "        for node in self.graph.nodes():\n",
    "            if self.graph.nodes[node]['state'] == 1:\n",
    "                all_true_nodes.append(node)\n",
    "            elif self.graph.nodes[node]['state'] == 2:\n",
    "                all_fake_nodes.append(node)\n",
    "            elif self.graph.nodes[node]['state'] == 0:\n",
    "                normal_nodes.append(node)\n",
    "        number_nodes = len(self.graph.nodes())\n",
    "        number_true_nodes = len(all_true_nodes) \n",
    "        number_fake_nodes = len(all_fake_nodes)\n",
    "        # terminal condition: over the MAX_STEP / less 1% nodes are normal nodes\n",
    "        terminated = bool(self.step_count >= MAX_STEP \n",
    "                        or len(normal_nodes)<=0.1 * number_nodes) \n",
    "        penatly = math.pow(1.05,self.add_number)\n",
    "        if not terminated:\n",
    "            if len(all_true_nodes)>len(all_fake_nodes):\n",
    "                reward = (len(all_true_nodes)  - len(all_fake_nodes) - penatly + 5)/(len(all_true_nodes) + len(all_fake_nodes))\n",
    "            else:\n",
    "                reward = (len(all_true_nodes)  - len(all_fake_nodes) - penatly)/(len(all_true_nodes) + len(all_fake_nodes))\n",
    "            done = False\n",
    "            self.step_count +=1\n",
    "        else: \n",
    "            # when this iteration is end, give a little big reward.\n",
    "            reward = 30\n",
    "            done = True\n",
    "            \n",
    "#             self.step_count >= MAX_STEP: \n",
    "#             # when this iteration is end, give a little big reward.\n",
    "#             reward = 20\n",
    "#             done = True\n",
    "#         elif len(normal_nodes)<=0.01 * number_nodes:\n",
    "#             reward = 30\n",
    "#             done = True\n",
    "            \n",
    "#         print(reward)\n",
    "        self.state = self.get_state()\n",
    "        return self.state, reward ,done \n",
    "    # select the initial seed set randomly\n",
    "    def select_initial_seeds(self, graph, seed_number):\n",
    "        node_number = graph.number_of_nodes()\n",
    "        start_node_index = [0] *seed_number\n",
    "        index_range = range(0,  node_number)\n",
    "        start_node_index = random.sample(index_range, seed_number)\n",
    "        for node in graph.nodes():\n",
    "            if node in start_node_index:\n",
    "                graph.nodes[node]['state'] = 1\n",
    "        return start_node_index\n",
    "    # select the initial seed set according to different rules\n",
    "    def select_initial_seeds_rules(self,graph,seed_number):\n",
    "        # 1 random 2 \"degree\",3 \"closeness\", 4\"betweenness\", 5\"eigenvector\"\n",
    "        action = random.randint(0,5)\n",
    "        start_node_index = []\n",
    "        centrality_scores = []\n",
    "        if action == 0:   \n",
    "            node_number = graph.number_of_nodes()\n",
    "            start_node_index = [0] *seed_number\n",
    "            index_range = range(0,  node_number)\n",
    "            start_node_index = random.sample(index_range, seed_number)\n",
    "        else:\n",
    "            if action == 1:\n",
    "                centrality_scores  = list(nx_centrality.degree_centrality(self.graph).values())\n",
    "            elif action == 2:\n",
    "                centrality_scores  = list(nx_centrality.degree_centrality(self.graph).values())\n",
    "            elif action == 3:\n",
    "                centrality_scores = list(nx_centrality.closeness_centrality(self.graph).values())\n",
    "            elif action == 4:\n",
    "                centrality_scores = list(nx_centrality.betweenness_centrality(self.graph).values())\n",
    "            elif action == 5:\n",
    "                centrality_scores = list(nx_centrality.eigenvector_centrality(self.graph).values())\n",
    "            for _ in range(seed_number):\n",
    "                max_number = max(centrality_scores)\n",
    "                index = centrality_scores.index(max_number)\n",
    "                while(graph.nodes[index]['state'] != 0):\n",
    "                    centrality_scores[index] = -1\n",
    "                    max_number = max(centrality_scores)\n",
    "                    index = centrality_scores.index(max_number)  \n",
    "                start_node_index.append(index)\n",
    "                centrality_scores[index] = -1\n",
    "        for node in graph.nodes():\n",
    "            if node in start_node_index:\n",
    "                graph.nodes[node]['state'] = 1\n",
    "        return start_node_index,action\n",
    "        \n",
    "    def add_seed(self,graph,seed_set,action,add_number):\n",
    "        # 1 random 2 \"degree\",3 \"closeness\", 4\"betweenness\", 5\"eigenvector\"\n",
    "        new_seed_set = []\n",
    "        new_seed_set = seed_set.copy()\n",
    "        centrality_scores = []\n",
    "        state0 = 0\n",
    "        for node in graph.nodes():\n",
    "            if graph.nodes[node]['state'] == 0:\n",
    "                state0 += 1\n",
    "        if state0 >= ADD_SEED_NUMBER:\n",
    "            if action == 1:\n",
    "                node_number = graph.number_of_nodes()\n",
    "                for _ in range(ADD_SEED_NUMBER):\n",
    "                    index = random.randint(0,node_number-1)\n",
    "                    while (index in seed_set) or (graph.nodes[index]['state'] in [1,2])  :\n",
    "                        index = random.randint(0,node_number-1)\n",
    "                    new_seed_set.append(index)\n",
    "                    graph.nodes[index]['state']  = 1\n",
    "\n",
    "            else: \n",
    "                if action == 2:\n",
    "                    centrality_scores  = list(nx_centrality.degree_centrality(self.graph).values())\n",
    "                elif action == 3:\n",
    "                    centrality_scores = list(nx_centrality.closeness_centrality(self.graph).values())\n",
    "                elif action == 4:\n",
    "                    centrality_scores = list(nx_centrality.betweenness_centrality(self.graph).values())\n",
    "                elif action == 5:\n",
    "                    centrality_scores = list(nx_centrality.eigenvector_centrality(self.graph).values())\n",
    "                for node in seed_set:\n",
    "                    centrality_scores[node] = -1\n",
    "                for _ in range(ADD_SEED_NUMBER):\n",
    "                    index = centrality_scores.index(max(centrality_scores))\n",
    "                    while(graph.nodes[index]['state'] != 0):\n",
    "                        index = centrality_scores.index(max(centrality_scores))\n",
    "                        # print(index)\n",
    "                        centrality_scores[index] = -1\n",
    "                    # print(\"add_seed, index:\",index)\n",
    "                    new_seed_set.append(index)\n",
    "                    graph.nodes[index]['state'] = 1\n",
    "                    centrality_scores[index] = -1\n",
    "        return new_seed_set\n",
    "    def get_state(self):\n",
    "        node_state = []\n",
    "        for node in self.graph.nodes():\n",
    "            node_state.append(self.graph.nodes[node]['state'])\n",
    "        return nx.to_numpy_array(self.graph), len(self.seed_set), node_state\n",
    "    \n",
    "    def diffusion_process(self, G ,true_active_set,fake_active_set,itertaion):\n",
    "        G = self.graph.copy()\n",
    "        true_active_nodes = true_active_set.copy()\n",
    "        fake_active_nodes = fake_active_set.copy()\n",
    "        # print(\"true_active_nodes begin:\",true_active_nodes)\n",
    "        # print(\"fake_active_nodes begin:\",fake_active_nodes)\n",
    "        for _ in range(itertaion):\n",
    "            tmp_true_nodes ={}\n",
    "            for v in true_active_nodes: \n",
    "                for nbr in G.neighbors(v):\n",
    "                    if G.nodes[nbr]['state'] in [0]:\n",
    "                        edge_data = G.get_edge_data(v, nbr)\n",
    "                        random_possibility = random.uniform(0, 1)\n",
    "                        if random_possibility < edge_data['weight']:\n",
    "                            G.nodes[nbr]['state'] == 3\n",
    "                            tmp_true_nodes.update({nbr:random_possibility})\n",
    "                            true_active_set.append(nbr)\n",
    "                    else:\n",
    "                        continue\n",
    "            tmp_fake_nodes ={}\n",
    "            for v in fake_active_nodes:\n",
    "                for nbr in G.neighbors(v):\n",
    "                    if G.nodes[nbr]['state'] in [0,3]:\n",
    "                        edge_data = G.get_edge_data(v, nbr)\n",
    "                        random_possibility = random.uniform(0, 1)\n",
    "                        if random_possibility < edge_data['weight']:\n",
    "                            tmp_fake_nodes.update({nbr:random_possibility})\n",
    "                            fake_active_set.append(nbr)\n",
    "                            G.nodes[nbr]['state'] == 4\n",
    "            true_active_nodes = list(tmp_true_nodes.keys())\n",
    "            fake_active_nodes = list(tmp_fake_nodes.keys())\n",
    "            for node in tmp_true_nodes.keys():\n",
    "                if node in tmp_fake_nodes.keys() :\n",
    "                    if tmp_true_nodes.get(node) >= tmp_fake_nodes.get(node):\n",
    "                        fake_active_set.remove(node)\n",
    "                        fake_active_nodes.remove(node)\n",
    "                    elif tmp_true_nodes.get(node) < tmp_fake_nodes.get(node):\n",
    "                        true_active_set.remove(node)\n",
    "                        true_active_nodes.remove(node)\n",
    "                else:\n",
    "                    continue\n",
    "            for node in true_active_set:\n",
    "                G.nodes[node]['state'] = 1\n",
    "            for node in fake_active_set:\n",
    "                G.nodes[node]['state'] = 2\n",
    "            # print(\"true_active_nodes\",true_active_set)\n",
    "            # print(\"fake_active_nodes\",fake_active_set)\n",
    "        return G,true_active_nodes,fake_active_nodes\n",
    "\n",
    "        \n",
    "    def get_image(self,Graph):\n",
    "        color_list = []\n",
    "        for node in Graph.nodes():\n",
    "            if Graph.nodes[node]['state'] == 0:\n",
    "                color_list.append('blue')\n",
    "            elif Graph.nodes[node]['state'] == 1:\n",
    "                color_list.append('green')\n",
    "            elif Graph.nodes[node]['state'] == 2:\n",
    "                color_list.append('red')\n",
    "        #nx.draw(Graph, node_color= color_list) \n",
    "        nx.draw_circular(Graph, node_color= color_list)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2773fe",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785ce85",
   "metadata": {},
   "source": [
    "##  Device: GPU/CPU\n",
    "Note:\n",
    "\n",
    "if you use Macbook with Apple M1/M2 core, please run the code in the Mac Device;\n",
    "\n",
    "if you use Windows with CUDA core, please run the code in the Windows Device;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e06f0d",
   "metadata": {},
   "source": [
    "### Mac Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a07dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if use MAC(Apple M1/M2) please run the follow codes\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b9cab",
   "metadata": {},
   "source": [
    "### Windows Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c982d5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3504cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Device Name: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name()\n",
    "    print(\"GPU Device Name:\", device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a98921e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuDNN Available\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.cudnn.is_available():\n",
    "    print(\"cuDNN Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec45066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# if use CUDA please run the follow codes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bdf574",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ba385d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim, learning_rate, gamma, epsilon, epsilon_decay):\n",
    "        self.q_network = QNetwork(state_dim, action_dim).to(device)\n",
    "        self.target_network = QNetwork(state_dim, action_dim).to(device)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=learning_rate)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.memory = deque(maxlen=10000)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(0, action_dim)\n",
    "        else:\n",
    "            state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "            q_values = self.q_network(state)\n",
    "#           q_values = self.q_network(torch.tensor(state, dtype=torch.float32))\n",
    "            return torch.argmax(q_values.cpu()).item()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        #state = torch.tensor(state).float().unsqueeze(0)  # ensure state is a tensor\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def train(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            #print(\"next_state:\", next_state)\n",
    "            #state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "            state_tensor = state_to_tensor(state).to(device)\n",
    "            #print(state_tensor.shape)\n",
    "            #print(self.q_network(state_tensor).shape)\n",
    "            action_index = torch.tensor(action, dtype=torch.long)\n",
    "            target = self.q_network(state_tensor)[0, action_index]\n",
    "            #target = self.q_network(state_tensor)[action]\n",
    "            if done:\n",
    "                target_value = reward\n",
    "            else:\n",
    "                next_state_tensor = state_to_tensor(next_state).to(device)\n",
    "                #next_state = torch.tensor(next_state, dtype=torch.float32).to(device)\n",
    "                next_q_values = self.target_network(next_state_tensor).detach()\n",
    "                target_value = reward + self.gamma * torch.max(next_q_values).item()\n",
    "\n",
    "            #loss = self.loss_fn(target, torch.tensor(float(target_value)))\n",
    "            loss = self.loss_fn(target, torch.tensor(float(target_value)).to(device))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.q_network.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.q_network.load_state_dict(torch.load(path))\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14baff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_tensor(state):\n",
    "    graph, num_seed_nodes, node_state = state\n",
    "    \n",
    "    graph_tensor = torch.tensor(graph, dtype=torch.float32).view(-1).unsqueeze(0)\n",
    "    num_seed_nodes_tensor = torch.tensor([num_seed_nodes], dtype=torch.float32).unsqueeze(0)\n",
    "    node_state_tensor = torch.tensor(node_state, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "#     state_tensor = torch.cat((graph_tensor, num_seed_nodes_tensor, node_state_tensor), dim=1)\n",
    "    state_tensor = torch.cat((num_seed_nodes_tensor, node_state_tensor), dim=1)\n",
    "    \n",
    "    return state_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "674d3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)# (2500 + 50 + 2) (10000 + 100 + 2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c102909",
   "metadata": {},
   "source": [
    "# Training Function\n",
    "The input valiable of train_dqn function:\n",
    "\n",
    "1. agent: the initialized Agent class\n",
    "2. env: the initialized Env class\n",
    "3. batch_size: BATCH_SIZE\n",
    "4. update_target_every: UPDATE;How many iterations to update the network\n",
    "5. dqn_agent_name: the name of DQN agent, the file extension is '.pth'\n",
    "6. brenchmark_action: Start benchmark comparison and specifying an action(1-5)\n",
    "7. Demo: Whether state should be displayed or saved each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "741bd718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(agent, env, episodes, batch_size, update_target_every,dqn_agent_name  = None,brenchmark_action = None,Demo = False):\n",
    "    state_history= []\n",
    "    rewards_list = []\n",
    "    for episode in range(episodes):\n",
    "        state,init_action = env.reset()\n",
    "        if brenchmark_action is not None:\n",
    "            init_action = brenchmark_action\n",
    "        #print(state)\n",
    "#         state = torch.tensor(state).float().unsqueeze(0)  # ensure state is a tensor\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            state_tensor = state_to_tensor(state)\n",
    "            #print(state_tensor)\n",
    "            if brenchmark_action is not None:\n",
    "                action = brenchmark_action\n",
    "            else:\n",
    "                action = agent.get_action(state_tensor)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            #print(next_state)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            agent.train(batch_size)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            if Demo:\n",
    "                state_history.append(state)  # Add current state to state_history\n",
    "        if not Demo:\n",
    "            state_history.append(state)\n",
    "        rewards_list.append(total_reward)\n",
    "        if episode % update_target_every == 0:\n",
    "            agent.update_target_network()\n",
    "\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "    if dqn_agent_name is not None:\n",
    "        torch.save(agent,dqn_agent_name)\n",
    "    return state_history, rewards_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395e81e",
   "metadata": {},
   "source": [
    "## Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1edae0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn_model(model, env, episodes):\n",
    "    rewards_list = []\n",
    "    for episode in range(episodes):\n",
    "        state,init_action = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            state_tensor = state_to_tensor(state)\n",
    "            action = model.get_action(state_tensor)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "        rewards_list.append(total_reward)\n",
    "\n",
    "        print(f\"Test Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "        \n",
    "    return rewards_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7dda4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn(agent, env, episodes):\n",
    "    rewards_list = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state,init_action = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            state_tensor = state_to_tensor(state)\n",
    "            action = agent.get_action(state_tensor)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "        rewards_list.append(total_reward)\n",
    "\n",
    "        print(f\"Test Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")\n",
    "        \n",
    "    return rewards_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18720b48",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57b671b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Global parameter of generate_random_graph\n",
    "FAKE_DIFF_ITER = 3 # the fake nodes diffusion iteration\n",
    "FAKE_SEED_NUM = 5 # the initial fake seed set number\n",
    "NODE_NUM = N_ca_GrQc # the intial graph nodes number\n",
    "EDGE_NUM = E_ca_GrQc # the intial graph edges number\n",
    "M_INDEX = 0 # the generate graph method index\n",
    "\n",
    "# the Global parameter of Env class\n",
    "ITERATION = 1 #control the diffusion times during the true and fake nodes antagonistic process\n",
    "MAX_STEP = 40 # control the max step of this epoch\n",
    "SEED_SIZE = 10 # the initial size of the seed set, the initial parameters of Env class.\n",
    "ADD_SEED_NUMBER = 1 # the number of nodes that are added to seed set\n",
    "\n",
    "# the Global parameter of Agentclass\n",
    "state_dim = NODE_NUM + 1 #state_dim: Dimension of state\n",
    "action_dim = 6 #action_dim:  Dimension of action space\n",
    "LR = 0.001#learning_rate: \n",
    "GAMMA = 0.99 # gamma:\n",
    "EPSILON = 1.0# epsilon: \n",
    "EPSILON_DECAY = 0.995 # epsilon_decay: \n",
    "# the Global parameter of train and test function\n",
    "batch_size = 128 #batch_size: \n",
    "UPDATE = 10 #update_target_every: \n",
    "ALL_EPISODES = 1 # total number of iteration times\n",
    "\n",
    "FIXED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d09ac49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5242, 14496)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ca_GrQc,E_ca_GrQc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4acaecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intial_train_graph_ca_GrQc,active_fake_set_ca_GrQc,intial_fake_set_ca_GrQc,all_fake_nodes_ca_GrQc = generate_random_graph(FAKE_DIFF_ITER,M_INDEX,FAKE_SEED_NUM,NODE_NUM, EDGE_NUM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25d68e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal nodes number: 5143\n",
      "true nodes number: 0\n",
      "fake nodes number: 99\n",
      "the edge of graph: 14496\n"
     ]
    }
   ],
   "source": [
    "statistic_draw_graph(intial_train_graph_ca_GrQc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76563c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_SIZE = len(active_fake_set_ca_GrQc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3096873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_ca_GrQc = Env(intial_train_graph_ca_GrQc, SEED_SIZE, active_fake_set_ca_GrQc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "717eb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_ca_GrQc = DQNAgent(state_dim, action_dim, LR , GAMMA, EPSILON, EPSILON_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465fbf2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_history_ca_GrQc, rewards_list_ca_GrQc = train_dqn(agent_ca_GrQc, env_ca_GrQc, ALL_EPISODES, batch_size ,UPDATE,dqn_agent_name =\"ca_GrQc.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19462365",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c37fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ca_GrQc,N_ca_GrQc, E_ca_GrQc = normalization_graph(G_ca_GrQc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_ca_GrQc = Env(G_ca_GrQc, SEED_SIZE, active_fake_set_ca_GrQc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"ca_GrQc.pth\")\n",
    "test_rewards_list_ca_GrQc = test_dqn_model(model, env_ca_GrQc, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d92ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "data = pd.DataFrame({'Rewards_test_ca_GrQc': test_rewards_list_ca_GrQc,'Rewards_train_ca_GrQc': rewards_list_ca_GrQc})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "data.to_excel('test_rewards_ca_GrQc.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67060c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
